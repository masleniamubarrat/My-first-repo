{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masleniamubarrat/My-first-repo/blob/main/26_11_thesis_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk"
      ],
      "metadata": {
        "id": "SePVAwDpsiep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "\n",
        "\n",
        "    stop_words = stopwords_list\n",
        "    tokens = text.split()\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "\n",
        "def preprocess_csv(input_file_path, output_file_path):\n",
        "    # Load the CSV into a DataFrame\n",
        "    data = pd.read_csv(input_file_path)\n",
        "\n",
        "    print(data['text'])\n",
        "\n",
        "    #Applying stopword removal to the 'text' column\n",
        "    data['preprocessed_text'] = data['text'].apply(remove_stopwords)\n",
        "\n",
        "     # Create a DataFrame with only the 'preprocessed_text' column\n",
        "    preprocessed_data = data[['preprocessed_text']]\n",
        "\n",
        "    # Write the preprocessed data to a new CSV file\n",
        "    preprocessed_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Define the path to your CSV file\n",
        "    input_file_path = '/content/drive/MyDrive/bengali_hate_v2.0.csv'\n",
        "\n",
        "    # Define the path to save the preprocessed file\n",
        "    output_file_path = '/content/drive/MyDrive/preprocessed_hate_speech.csv'\n",
        "    #stop_words = bengali_stopwords\n",
        "    #print(stop_words)\n",
        "\n",
        "    preprocess_csv(input_file_path, output_file_path)\n",
        "\n",
        "# Call the main function\n",
        "main()"
      ],
      "metadata": {
        "id": "VQGNdtpRs0Wi",
        "outputId": "5b129302-7e42-4044-a87f-5e2ed86fc414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       বৌদির দুধ দেকে তো আমার ই চোখ ঠিক ছিলো না - পোল...\n",
            "1       এই সরকার কে যারা নির্লজ্জের মত সাপোর্ট দিয়েছে ...\n",
            "2       পিলখানা হত্যাকান্ড বাংলাদেশের প্রতিরক্ষা ব্যবস...\n",
            "3       ভারতের অর্থনীতি নিয়ে আপনাদের ভাবতে হবে না। ভা...\n",
            "4                 খানকির পুলা মালায়নদের মেরে সাফা করে ফেল\n",
            "                              ...                        \n",
            "5693    জুতা যতই দামি হোক তার স্থান পায়ে তার স্থান কখ...\n",
            "5694    আমাদের দেশ ছোট বলে ভারতের চেয়ে পিছিয়ে, না হয়...\n",
            "5695    হিন্দুদের মধ্যে এগুলো হয় এটাই তার বাস্তব প্রমা...\n",
            "5696           দেখলে মনে হয় শালী একটা অস্ট্রেলিয়ান গাভী \n",
            "5697    ভাই আমি আপনার সাথে একমত। আর নারী নেতৃত্বে থাকত...\n",
            "Name: text, Length: 5698, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bengali_stopwords = set(bengali_stopwords)\n",
        "print(bengali_stopwords)"
      ],
      "metadata": {
        "id": "wsgKDPYEDYMv",
        "outputId": "801c0302-7117-49c6-aaa5-8c08bdc9c8ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'হয়ে', 'সেটা', 'যায়', 'ঠিক', 'কোন', 'তাদের', 'পারে', 'যেতে', 'বিশেষ', 'যারা', 'ছিল', 'করবে', 'থেকেই', 'এটি', 'জনের', 'তাঁর', 'করেই', 'করাই', 'প্রায়', 'ওঁরা', 'মতো', 'আদ্যভাগে', 'আবার', 'খুব', 'প্রতি', 'নেই', 'যাঁরা', 'উত্তর', 'সহিত', 'যান', 'এমন', 'মধ্যেও', 'এরা', 'এঁদের', 'হলো', 'সব', 'টি', 'নিজে', 'গেছে', 'ই', 'এখানেই', 'ওদের', 'মাত্র', 'দিতে', 'ধরে', 'অনেক', 'তাঁকে', 'দেওয়া', 'করায়', 'কবে', 'দেওয়া', 'বলেন', 'তাহলে', 'নাগাদ', 'এক্', 'সঙ্গে', 'রয়েছে', 'যার', 'হয়নি', 'হয়েই', 'মাধ্যমে', 'এখন', 'হত', 'জানিয়েছে', 'যখন', 'ফের', 'হাজার', 'আপনি', 'না', 'করিয়া', 'হয়েছিল', 'নিয়ে', 'এতে', 'বলা', 'অনুযায়ী', 'দিন', 'মোটেই', 'তাহাতে', 'মতোই', 'করেন', 'চেষ্টা', 'এর', 'দুটি', 'আর', 'বা', 'এই', 'আমাদের', 'কে', 'নানা', 'চেয়ে', 'পারেন', 'জন্যওজে', 'হলেই', 'সমস্ত', 'যেখানে', 'ধামার', 'এবং', 'কাজ', 'কেউই', 'হওয়ার', 'হতেই', 'পর', 'তাহা', 'উচিত', 'যদি', 'বলে', 'সবার', 'দেয়', 'এঁরা', 'এ', 'গিয়েছে', 'সহ', 'উনি', 'রকম', 'কেন', 'যাঁর', 'শুরু', 'জে', 'হয়েছে', 'উপরে', 'ধরা', 'যাবে', 'সি', 'অর্থাত', 'এটাই', 'ওর', 'বহু', 'তোমার', 'ওঁর', 'থেকে', 'পি', 'কিছুই', 'গেলে', 'তত', 'কয়েক', 'আপনার', 'আগে', 'পরেও', 'হৈলে', 'করছেন', 'তারৈ', 'থাকবে', 'বন', 'নিজেই', 'কাজে', 'হন', 'যত', 'যতটা', 'অথচ', 'হচ্ছে', 'কিন্তু', 'অন্তত', 'নেওয়া', 'যিনি', 'কারণ', 'থাকা', 'বাদে', 'জানিয়ে', 'হওয়ায়', 'নতুন', 'হল', 'হতে', 'ছাড়াও', 'যাওয়া', 'নয়', 'এমনি', 'আমি', 'দিয়েছে', 'তাঁরা', 'লক্ষ', 'ক্ষেত্রে', 'একই', 'অবধি', 'প্রাথমিক', 'তবু', 'নয়', 'এমনকী', 'চার', 'প্রথম', 'মনে', 'যে', 'রেখে', 'হয়', 'পরেই', 'তেমন', 'বলল', 'অনেকেই', 'বসে', 'করিতে', 'তিনঐ', 'এদের', 'হলে', 'যাওয়ার', 'ও', 'গোটা', 'কখনও', 'গুলি', 'করেছে', 'তারা', 'বললেন', 'সে', 'জানা', 'সামনে', 'প্রায়', 'যাকে', 'কেখা', 'হোক', 'তুমি', 'পর্যন্ত', 'তাতে', 'পেয়্র্', 'ব্যবহার', 'যদিও', 'হওয়া', 'করি', 'চালু', 'কারও', 'হলেও', 'যেমন', 'জানানো', 'করছে', 'পাওয়া', 'দুটো', 'সেটাই', 'করেছিলেন', 'করবেন', 'বিভিন্ন', 'তুলে', 'তাকে', 'জানতে', 'র', 'দ্বারা', 'পক্ষে', 'পরে', 'বদলে', 'বার', 'আজ', 'জনকে', 'তবে', 'কত', 'করলেন', 'হয়তো', 'বেশ', 'যাওয়া', 'নাই', 'হবে', 'দেখতে', 'ওরা', 'হইতে', 'এব', 'আগামী', 'জন', 'দিকে', 'ছিলেন', 'অনেকে', 'নিয়ে', 'মধ্যভাগে', 'জন্য', 'রাখা', 'বরং', 'কেউ', 'হইয়া', 'মধ্যেই', 'অথবা', 'সাধারণ', 'এত', 'তিনিও', 'একে', 'অতএব', 'বেশি', 'ওঁদের', 'আমরা', 'থাকায়', 'একটি', 'ছাড়া', 'কিংবা', 'তা', 'কয়েকটি', 'হবেন', 'মোট', 'আমাকে', 'করার', 'আছে', 'করেছেন', 'সঙ্গেও', 'দেখা', 'বলেছেন', 'এটা', 'সেই', 'কি', 'তথা', 'ইহা', 'থাকে', 'যাতে', 'করে', 'করলে', 'তাঁাহারা', 'আমার', 'যথেষ্ট', 'দু', 'এল', 'কোনো', 'জানায়', 'হয়', 'এখানে', 'কাছে', 'একবার', 'ইত্যাদি', 'তো', 'থাকেন', 'ব্যাপারে', 'যেন', 'কাউকে', 'চায়', 'জ্নজন', 'গিয়ে', 'সুতরাং', 'আরও', 'আই', 'করা', 'বি', 'সম্প্রতি', 'প্রযন্ত', 'তখন', 'ফিরে', 'হইবে', 'নিজের', 'দেওয়ার', 'নাকি', 'শুধু', 'তাই', 'ওকে', 'তাও', 'এতটাই', 'দেন', 'করতে', 'বক্তব্য', 'কয়েক', 'যাচ্ছে', 'সেখান', 'স্পষ্ট', 'আগেই', 'ভাবে', 'চলে', 'যাদের', 'পারি', 'উপর', 'থেকেও', 'দিয়ে', 'ভাবেই', 'বিষয়টি', 'নিতে', 'ওই', 'অবশ্য', 'নিজেদের', 'দিয়েছেন', 'নেওয়ার', 'পাচ', 'কোটি', 'ঐ', 'কিছু', 'তাহার', 'কোনও', 'এখনও', 'কাছ', 'হিসাবে', 'দেখে', 'চান', 'হয়েছেন', 'তিনি', 'থাকবেন', 'সেটাও', 'এস', 'বিনা', 'সেখানে', 'দিলেন', 'কী', 'বলতে', 'যা', 'দুই', 'নেওয়া', 'তাঁদের', 'করিয়ে', 'সেটি', 'পেয়ে', 'গেল', 'স্বয়ং', 'গিয়ে', 'কমনে', 'এবার', 'ওখানে', 'এসে', 'অন্য', 'প্রভৃতি', 'তার', 'মধ্যে', 'তারপর', 'ফলে'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_text = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Split the text by newline character to create a list of stopwords\n",
        "more_stopwords = stopwords_text.strip().split('\\n')"
      ],
      "metadata": {
        "id": "rOPql6OFEGrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:10])"
      ],
      "metadata": {
        "id": "uy88rdT6LqLd",
        "outputId": "440e1e60-4da5-400c-ecb2-abe26ebca225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0    words\n",
            "0           0       অই\n",
            "1           1   অগত্যা\n",
            "2           2   অত: পর\n",
            "3           3     অতএব\n",
            "4           4      অথচ\n",
            "5           5     অথবা\n",
            "6           6     অধিক\n",
            "7           7    অধীনে\n",
            "8           8  অধ্যায়\n",
            "9           9  অনুগ্রহ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to your Excel file in your Google Drive\n",
        "file_path = '/content/drive/MyDrive/stopwords_bangla.xlsx'\n",
        "\n",
        "# Read the Excel file\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Extract contents from the 'words' column into a Python list\n",
        "stopwords_list = data['words'].tolist()\n",
        "\n",
        "# Display the first few elements of the list\n",
        "print(words_list[:10])  # Change the index to view more or fewer elements\n",
        "\n",
        "# Now you have the contents of the 'words' column in the 'data' DataFrame as a Python list named 'words_list'\n"
      ],
      "metadata": {
        "id": "GJwzPIYzHKc9",
        "outputId": "91f1a281-9a44-43d9-b85a-ce482d5eaf6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['অই', 'অগত্যা', 'অত: পর', 'অতএব', 'অথচ', 'অথবা', 'অধিক', 'অধীনে', 'অধ্যায়', 'অনুগ্রহ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = len(words_list)\n",
        "print(num)"
      ],
      "metadata": {
        "id": "F-VLB-L0Izoi",
        "outputId": "dcf5db15-feea-4b98-9d86-e4f6dcb963ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def remove_stopwords(text):\n",
        "\n",
        "\n",
        "    stop_words = stopwords_list\n",
        "    tokens = text.split()\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "def preprocess_xlsx(input_file_path, output_file_path):\n",
        "    # Load the Excel file into a DataFrame\n",
        "    data = pd.read_excel(input_file_path)\n",
        "\n",
        "    # Get the column index based on its position (0-indexed)\n",
        "    column_index = 1  # Assuming the 'base_diagram' column is the second column (index 1)\n",
        "\n",
        "    # Applying stopword removal to the 'base_diagram' column using its index\n",
        "    data['processed_text'] = data.iloc[:, column_index].apply(remove_stopwords)\n",
        "\n",
        "    # Selecting 'processed_text' and 'degree_of_toxicity' columns\n",
        "    processed_data = data.iloc[:, [column_index, -1]]  # Assuming 'degree_of_toxicity' is the last column\n",
        "\n",
        "    # Write the processed data to a new CSV file\n",
        "    processed_data.to_csv(output_file_path, index=False)\n",
        "def main():\n",
        "    # Define the path to your Excel file\n",
        "    input_file_path = '/content/drive/MyDrive/hate_lexicons.xlsx'\n",
        "\n",
        "    # Define the path to save the preprocessed CSV file\n",
        "    output_file_path = '/content/drive/MyDrive/preprocessed_hate_lexicons.csv'\n",
        "\n",
        "    preprocess_xlsx(input_file_path, output_file_path)\n",
        "\n",
        "# Call the main function\n",
        "main()\n"
      ],
      "metadata": {
        "id": "OFn7PR5oYqyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}